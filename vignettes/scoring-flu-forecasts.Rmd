---
title: "Scoring Flusight submissions using scoringutils"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Scoring Flusight submissions using scoringutils}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "svg",
  fig.ext = "svg",
  fig.height = 16,
  fig.width = 8
)
```

```{r setup, message = FALSE}
library(forecasttools)
library(scoringutils)
library(dplyr)
library(ggplot2)
library(knitr)
```

In this vignette, we use `forecasttools` to capture the current state of the FluSight forecast hub (see [here](https://github.com/cdcepi/FluSight-forecast-hub)), and then score the forecasts according to a [proper scoring rule](https://en.wikipedia.org/wiki/Scoring_rule). We do the scoring with [`scoringutils`](https://github.com/epiforecasts/scoringutils).

### Generating a table of forecasts against truth data.

First, we create a table of quantile forecasts formatted to work with `scoringutils` functions using `hub_to_scorable_quantiles()`. Generally, we expect users to use `hub_to_scorable_quantiles()` with a local path to the forecast repository which updates from GitHub by default. In this case, we download a copy of the Hub from GitHub.

```{r}
hub_url <- "https://github.com/cdcepi/FluSight-forecast-hub"
hub_path <- fs::path(withr::local_tempdir(), "flusight-hub")
download_hub(
  hub_url = hub_url,
  hub_path = hub_path,
  force = TRUE
)
```

```{r, include = FALSE}
## use a specific commit to future-proof the vignette
gert::git_branch_create(
  branch = "flu-scoring-vignette-temp",
  repo = hub_path,
  force = FALSE,
  checkout = TRUE,
  ref = "6ae6919"
)
```

The FluSight hub currently has a single "target" for quantile forecasts: epiweekly incident Influenza hospital admissions. It provides a timeseries of that data in a file named [`target-data/target-hospital-admissions.csv'](https://github.com/cdcepi/FluSight-forecast-hub/blob/6ae6919865417a2557773faa5f7354a0329baa4c/target-data/target-hospital-admissions.csv).

Unlike the schema for forecasts, the schema for target data is not yet standardized across Hubs. `hub_to_scorable_quantiles()` asks you to provide the relative path to the target data you want within the hub, as well as what ID columns (besides date) should be used to join it to forecasts:

```{r}
target_data_path <- fs::path("target-data",
  "target-hospital-admissions",
  ext = "csv"
)
forecast_and_target <- hub_to_scorable_quantiles(hub_path,
  target_data_rel_path =
    target_data_path,
  id_cols = "location"
)
```

There were `r forecast_and_target$model_id |> unique() |> length()` different models that had been submitted to FluSight as of the [copy examined in this vignette](https://github.com/cdcepi/FluSight-forecast-hub/commit/6ae69198654)

```{r}
unique(forecast_and_target$model_id)
```

There are `r forecast_and_target$location |> unique() |> na.omit() |> length()` locations, either states or territories, for which there are available fforecasts. They are stored as two-digit codes, but can re-code them as the more familiar USPS-style two-letter abbreviations via `us_loc_code_to_abbr()`:

```{r}
unique(forecast_and_target$location)

forecast_and_target <- forecast_and_target |>
  mutate(location = us_loc_code_to_abbr(location))

unique(forecast_and_target$location)
```

### Tabular scoring of forecasts

`scoringutils` provides various forecast evaluation metrics including interval scores, skill relative to a chosen baseline, and coverage at different prediction quantiles. Here we show the metrics for US overall forecasts by model for all forecast dates so far, rounding to two significant figures


```{r}
chosen_location <- "US"

forecast_and_target |>
  filter(location == !!chosen_location) |>
  score() |>
  summarise_scores(
    by = "model_id",
    relative_skill = TRUE,
    baseline = "FluSight-ensemble"
  ) |>
  summarise_scores(
    by = "model_id",
    fun = signif,
    digits = 2
  ) |>
  kable()
```
